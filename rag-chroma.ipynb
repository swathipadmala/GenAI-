{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c39b30",
   "metadata": {},
   "source": [
    "# save the open ai key in environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904f6907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"your_api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70402eba",
   "metadata": {},
   "source": [
    "# import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2855eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "CHROMA_PATH = \".\\chroma5\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607f5ca7",
   "metadata": {},
   "source": [
    "# load the data into chroma db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a18e1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = PyPDFLoader(\"C:\\\\Users\\\\padma\\\\Downloads\\\\Task_for_internship\\\\The-Jungle-Books-text.pdf\")\n",
    "\n",
    "documents = loaders.load()\n",
    "\n",
    "db = Chroma.from_documents(\n",
    "    documents,\n",
    "    OpenAIEmbeddings(),\n",
    "    persist_directory=CHROMA_PATH\n",
    "  )\n",
    "db.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e67d266",
   "metadata": {},
   "source": [
    "# defining prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "055d949b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    " - -\n",
    "Answer the question based on the above context: {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a6ba8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf12b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(query_text):\n",
    "  \"\"\"\n",
    "  Query a Retrieval-Augmented Generation (RAG) system using Chroma database and OpenAI.\n",
    "  Args:\n",
    "    - query_text (str): The text to query the RAG system with.\n",
    "  Returns:\n",
    "    - formatted_response (str): Formatted response including the generated text and sources.\n",
    "    - response_text (str): The generated response text.\n",
    "  \"\"\"\n",
    "  # YOU MUST - Use same embedding function as before\n",
    "  embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "  # Prepare the database\n",
    "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
    "  \n",
    "  # Retrieving the context from the DB using similarity search\n",
    "  results = db.similarity_search_with_relevance_scores(query_text, k=3)\n",
    "\n",
    "  # Check if there are any matching results or if the relevance score is too low\n",
    "  # if len(results) == 0 or results[0][1] < 0.7:\n",
    "  #   print(f\"Unable to find matching results.\")\n",
    "\n",
    "  # Combine context from matching documents\n",
    "  context_text = \"\\n\\n - -\\n\\n\".join([doc.page_content for doc, _score in results])\n",
    " \n",
    "  # Create prompt template using context and query text\n",
    "  prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
    "  prompt = prompt_template.format(context=context_text, question=query_text)\n",
    "  \n",
    "  # Initialize OpenAI chat model\n",
    "  model = ChatOpenAI()\n",
    "\n",
    "  # Generate response text based on the prompt\n",
    "  response_text = model.predict(prompt)\n",
    " \n",
    "   # Get sources of the matching documents\n",
    "  sources = [doc.metadata.get(\"source\", None) for doc, _score in results]\n",
    " \n",
    "  # Format and return response including generated text and sources\n",
    "  formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
    "  return formatted_response, response_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552df65",
   "metadata": {},
   "source": [
    "# Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ea7973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\padma\\AppData\\Local\\Temp\\ipykernel_21004\\3764950876.py:14: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
      "C:\\Users\\padma\\AppData\\Local\\Temp\\ipykernel_21004\\3764950876.py:34: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response_text = model.predict(prompt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The characters in \"The Jungle Book\" include Mowgli, Baloo, Bagheera, Shere Khan, and Kaa.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"what are the characters are their in this story\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0f3033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rudyard Kipling\n"
     ]
    }
   ],
   "source": [
    "query_text=\"who is author of this book\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c1b5bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The theme of \"The Jungle Book\" is about the importance of family, friendship, and the balance between the laws of the jungle and human society. It also explores themes of identity, belonging, and the struggle between civilization and nature.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"what is the theme of this story\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffde6d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context provided, the best friends mentioned in the verses are Bhîßma, Kar√a, K®pa, Açvatthåmå, Vikar√a, Bhüriçravå, and Jayadratha.\n"
     ]
    }
   ],
   "source": [
    "query_text=\"who are the best friends\"\n",
    "formatted_response, response_text = query_rag(query_text)\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd6cba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
