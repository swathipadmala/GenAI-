{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61363bbd",
   "metadata": {},
   "source": [
    "# set up open ai key in environmental variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fa2276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"your_api_key\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8fa0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_llm():\n",
    "        from langchain_openai import ChatOpenAI\n",
    "        llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0) #gpt-4o-mini\n",
    "        return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc78edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iporting prompt template\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "def load_prompt():\n",
    "        prompt = \"\"\" You need to answer the question in the sentence as same as in the  pdf content. . \n",
    "        Given below is the context and question of the user.\n",
    "        context = {context}\n",
    "        question = {question}\n",
    "        if the answer is not in the pdf , answer \"i donot know what the hell you are asking about\"\n",
    "         \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(prompt)\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35495881",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d075c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "def load_knowledgeBasee():\n",
    "        embeddings=OpenAIEmbeddings()\n",
    "        DB_FAISS_PATH = 'vectorstore/db_faiss'\n",
    "        db = FAISS.load_local(DB_FAISS_PATH, embeddings,allow_dangerous_deserialization=True)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b50270",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledgeBase=load_knowledgeBasee()\n",
    "llm=load_llm()\n",
    "prompt=load_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7154b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0d020e",
   "metadata": {},
   "source": [
    "# asking queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb6a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "query = \"who is krishna\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b089fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Krishna is described as the reservoir of pleasure, the primeval cause of everything, and the cause of all causes in the Brahma-saµhitå. He is also known as Govinda, one who gives pleasure to the senses.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d79aa678",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who is arjuna\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "beeb2288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arjuna is an accomplished student of Vedic thought and an associate of Çrî K®ß√a, but for the benefit of those who will study this erudite conversation in the future, Arjuna is feigning bewilderment and confusion just to encourage the discourse. Arjuna is considered a liberated personality and thus he is actually above ignorance and bewilderment.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c42222",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"can you tell me about pandavas and how many members are their in this pandavas\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "612ec236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The På√∂avas are the sons of På√∂u and there are five members in the På√∂avas - Yudhiß†hira, Arjuna, Bhîma, Nakula, and Sahadeva.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f437a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who is mother of pandavas\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cbdd2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The mother of the På√∂avas is Queen Kuntî.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55184d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who is father of pandav\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fafa233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pandu is the father of the Pandavas.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8cb7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who publisher of this book\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "44161b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GAURANGA VANI PUBLISHERS'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8004904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"can you tell me about the motive of this story\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2640046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The motive of the story is to elevate one beyond the bodily concept of life to the plane of consciousness or understanding the nature of the self.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8b293bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who won the kurukshetra\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68db2548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The På√∂avas won the Kurukshetra war.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd6a117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how many members are their in kauravas\"\n",
    "if True:\n",
    "    similar_embeddings=knowledgeBase.similarity_search(query)\n",
    "    similar_embeddings=FAISS.from_documents(documents=similar_embeddings, embedding=OpenAIEmbeddings())\n",
    "                \n",
    "    #creating the chain for integrating llm,prompt,stroutputparser\n",
    "    retriever = similar_embeddings.as_retriever()\n",
    "    rag_chain = (\n",
    "                        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "                        | prompt\n",
    "                        | llm\n",
    "                        | StrOutputParser()\n",
    "                    )\n",
    "                \n",
    "    response=rag_chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10879119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There were 100 members in the Kauravas.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e2675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
